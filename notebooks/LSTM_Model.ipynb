{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j07H1iHCEjKY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "from termcolor import colored"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataclean_test.csv\n",
        "print(colored(\"Loading train and test data...\", \"yellow\"))\n",
        "train_data = pd.read_csv('/content/clean_train.csv')\n",
        "test_data = pd.read_csv('/content/clean_test.csv')\n",
        "print(colored(\"Data loaded successfully.\", \"green\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6YB1l2bFKIA",
        "outputId": "f66ffcdc-7464-450c-8890-1cdc62d2f83c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading train and test data...\n",
            "Data loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and Padding\n",
        "print(colored(\"Tokenizing and padding data...\", \"yellow\"))\n",
        "tokenizer = Tokenizer(num_words=5000, split=' ')\n",
        "tokenizer.fit_on_texts(train_data['Clean_tweet'].astype(str).values)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['Clean_tweet'].astype(str).values)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['Clean_tweet'].astype(str).values)\n",
        "\n",
        "max_len = max([len(x) for x in train_sequences])\n",
        "train_tweets = pad_sequences(train_sequences, maxlen=max_len)\n",
        "test_tweets = pad_sequences(test_sequences, maxlen=max_len)\n",
        "print(colored(\"Tokenization and padding complete.\", \"green\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpu7Z95aFQBm",
        "outputId": "374041b6-4a44-46ab-abbe-629a926cc90d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing and padding data...\n",
            "Tokenization and padding complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM Model\n",
        "print(colored(\"Creating the LSTM model...\", \"yellow\"))\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=128, input_length=max_len),\n",
        "    SpatialDropout1D(0.4),\n",
        "    LSTM(256, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "GjssgBx3FVud",
        "outputId": "af69aec8-bb52-4747-c6cc-f2ea2178c755"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the LSTM model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ spatial_dropout1d (\u001b[38;5;33mSpatialDropout1D\u001b[0m) │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ spatial_dropout1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>) │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "print(colored(\"Training the LSTM model...\", \"green\"))\n",
        "history = model.fit(\n",
        "    train_tweets, pd.get_dummies(train_data['Sentiment']).values,\n",
        "    epochs=10, batch_size=128, validation_split=0.2, verbose=1\n",
        ")\n",
        "print(colored(\"Model training complete.\", \"green\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhQl4NbSFa5L",
        "outputId": "b94908d6-6e8d-4413-87cb-5a43bf92f1a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the LSTM model...\n",
            "Epoch 1/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m602s\u001b[0m 300ms/step - accuracy: 0.7281 - loss: 0.5316 - val_accuracy: 0.7755 - val_loss: 0.4713\n",
            "Epoch 2/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 297ms/step - accuracy: 0.7782 - loss: 0.4646 - val_accuracy: 0.7800 - val_loss: 0.4637\n",
            "Epoch 3/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m656s\u001b[0m 314ms/step - accuracy: 0.7871 - loss: 0.4489 - val_accuracy: 0.7800 - val_loss: 0.4636\n",
            "Epoch 4/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m644s\u001b[0m 295ms/step - accuracy: 0.7924 - loss: 0.4381 - val_accuracy: 0.7816 - val_loss: 0.4649\n",
            "Epoch 5/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 294ms/step - accuracy: 0.7966 - loss: 0.4309 - val_accuracy: 0.7811 - val_loss: 0.4643\n",
            "Epoch 6/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 295ms/step - accuracy: 0.8019 - loss: 0.4207 - val_accuracy: 0.7801 - val_loss: 0.4685\n",
            "Epoch 7/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 295ms/step - accuracy: 0.8058 - loss: 0.4142 - val_accuracy: 0.7792 - val_loss: 0.4699\n",
            "Epoch 8/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 293ms/step - accuracy: 0.8108 - loss: 0.4061 - val_accuracy: 0.7786 - val_loss: 0.4754\n",
            "Epoch 9/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 294ms/step - accuracy: 0.8138 - loss: 0.3994 - val_accuracy: 0.7796 - val_loss: 0.4766\n",
            "Epoch 10/10\n",
            "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 293ms/step - accuracy: 0.8194 - loss: 0.3909 - val_accuracy: 0.7797 - val_loss: 0.4902\n",
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model and Tokenizer\n",
        "model.save('lstm_sentiment_model.h5')\n",
        "tokenizer_json = tokenizer.to_json()\n",
        "with open('tokenizer.json', 'w') as f:\n",
        "    f.write(tokenizer_json)\n",
        "print(colored(\"Model and tokenizer saved successfully.\", \"green\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c2yajYdFeTq",
        "outputId": "865a0c00-e8f9-4b45-d30c-ee921bac86bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "print(colored(\"Evaluating the LSTM model on test data...\", \"yellow\"))\n",
        "score, accuracy = model.evaluate(test_tweets, pd.get_dummies(test_data['Sentiment']).values, batch_size=128)\n",
        "print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "print(colored(\"Model evaluation complete.\", \"green\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDMOYcKvFh6W",
        "outputId": "72ea3b0f-8ade-423e-ab13-065db26a3e6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the LSTM model on test data...\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 97ms/step - accuracy: 0.8356 - loss: 0.3595\n",
            "Test accuracy: 82.46%\n",
            "Model evaluation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NuPEcYNvh06Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Tokenizer for New Predictions\n",
        "print(colored(\"Loading the saved model and tokenizer...\", \"yellow\"))\n",
        "loaded_model = load_model('lstm_sentiment_model.h5')\n",
        "with open('tokenizer.json') as f:\n",
        "    loaded_tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(f.read())\n",
        "print(colored(\"Model and tokenizer loaded successfully.\", \"green\"))"
      ],
      "metadata": {
        "id": "_YA4l0OQFmz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a058ef99-e501-4931-ecff-534fd921ab34"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the saved model and tokenizer...\n",
            "Model and tokenizer loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "L02Q911nljQ6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on a New Example\n",
        "def predict_sentiment(text):\n",
        "    sequence = loaded_tokenizer.texts_to_sequences([text])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
        "    prediction = loaded_model.predict(padded_sequence)\n",
        "    sentiment = \"Positive\" if np.argmax(prediction) == 1 else \"Negative\"\n",
        "    print(colored(f\"Predicted Sentiment: {sentiment}\", \"blue\"))"
      ],
      "metadata": {
        "id": "sRtFAucJFqAm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the prediction with an example\n",
        "example_text = \"I'm really excited about this product, it's amazing!\"\n",
        "predict_sentiment(example_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OClkpbZCFse8",
        "outputId": "b2987056-75e6-4d8f-8be2-edadd1ebf822"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Predicted Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2plygVuDh53r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}